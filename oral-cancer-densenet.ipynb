{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":2449781,"datasetId":1482677,"databundleVersionId":2492129},{"sourceType":"datasetVersion","sourceId":14793739,"datasetId":9458268,"databundleVersionId":15648104},{"sourceType":"datasetVersion","sourceId":7716037,"datasetId":4426002,"databundleVersionId":7815312},{"sourceType":"datasetVersion","sourceId":14793807,"datasetId":9458322,"databundleVersionId":15648176}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport torch.nn as nn\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------\n# Config\n# ------------------------\nDATA_DIR = \"/kaggle/input/datasets/zaidpy/oral-cancer-dataset/Oral cancer Dataset 2.0/OC Dataset kaggle new\"\nBATCH_SIZE = 16\nEPOCHS = 20\nLR = 1e-4\nIMG_SIZE = 224\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------\n# Reproducibility\n# ------------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# ------------------------\n# Transforms\n# ------------------------\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------\n# Class Weights\n# ------------------------\ntargets = [full_dataset.targets[i] for i in train_dataset.indices]\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(targets),\n    y=targets\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom sklearn.metrics import (precision_score, recall_score, f1_score,\n                             roc_auc_score, roc_curve, auc,\n                             confusion_matrix, classification_report)\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold\nfrom torch.utils.data import Subset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset without transform first\nfull_dataset = datasets.ImageFolder(DATA_DIR)\n\nclass_names = full_dataset.classes\ntargets = full_dataset.targets\ntargets = np.array(targets)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# First split: Train (70%) and Temp (30%)\ntrain_idx, temp_idx = train_test_split(\n    np.arange(len(targets)),\n    test_size=0.30,\n    stratify=targets,\n    random_state=42\n)\n\n# Second split: Temp -> Val (15%) & Test (15%)\nval_idx, test_idx = train_test_split(\n    temp_idx,\n    test_size=0.50,\n    stratify=targets[temp_idx],\n    random_state=42\n)\n\nprint(f\"Train size: {len(train_idx)}\")\nprint(f\"Val size: {len(val_idx)}\")\nprint(f\"Test size: {len(test_idx)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create separate dataset objects\ntrain_dataset = Subset(\n    datasets.ImageFolder(DATA_DIR, transform=train_transform),\n    train_idx\n)\n\nval_dataset = Subset(\n    datasets.ImageFolder(DATA_DIR, transform=val_transform),\n    val_idx\n)\n\ntest_dataset = Subset(\n    datasets.ImageFolder(DATA_DIR, transform=val_transform),\n    test_idx\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ntrain_targets = targets[train_idx]\n\nfold_results = []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_fold_f1 = 0.0\nbest_model_path = \"/kaggle/working/best_cv_model.pkl\"\n\nfor fold, (train_fold_idx, val_fold_idx) in enumerate(skf.split(train_idx, train_targets)):\n\n    print(f\"\\n========== Fold {fold+1} ==========\")\n\n    # Create datasets (same as before)\n    fold_train_idx = np.array(train_idx)[train_fold_idx]\n    fold_val_idx = np.array(train_idx)[val_fold_idx]\n\n    fold_train_dataset = Subset(\n        datasets.ImageFolder(DATA_DIR, transform=train_transform),\n        fold_train_idx\n    )\n\n    fold_val_dataset = Subset(\n        datasets.ImageFolder(DATA_DIR, transform=val_transform),\n        fold_val_idx\n    )\n\n    fold_train_loader = DataLoader(fold_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    fold_val_loader = DataLoader(fold_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    # New model per fold\n    model = models.densenet169(pretrained=True)\n    model.classifier = nn.Linear(model.classifier.in_features, 2)\n    model = model.to(DEVICE)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n\n    # Train\n    for epoch in range(5):\n        model.train()\n        for images, labels in fold_train_loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n    # Validate\n    model.eval()\n    y_true, y_pred = [], []\n\n    with torch.no_grad():\n        for images, labels in fold_val_loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1)\n\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    fold_f1 = f1_score(y_true, y_pred)\n    print(f\"Fold {fold+1} F1: {fold_f1:.4f}\")\n\n    # Save best fold model\n    if fold_f1 > best_fold_f1:\n        best_fold_f1 = fold_f1\n\n        torch.save({\n            \"model_state_dict\": model.state_dict(),\n            \"class_names\": class_names,\n            \"img_size\": IMG_SIZE\n        }, best_model_path)\n\n        print(f\"Saved best fold model at {best_model_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SAVE_PATH = \"/kaggle/working/best_cv_model.pkl\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------\n# Load best model and evaluate on TEST set only\n# ------------------------\ncheckpoint = torch.load(SAVE_PATH, map_location=DEVICE)\nmodel_best = models.densenet169(pretrained=False)\nmodel_best.classifier = nn.Linear(model_best.classifier.in_features, len(class_names))\nmodel_best.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel_best = model_best.to(DEVICE)\nmodel_best.eval()\n\n# Collect test predictions and probabilities\ny_true_test, y_pred_test, y_prob_test = [], [], []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        outputs = model_best(images)                     # (N, C)\n        probs = F.softmax(outputs, dim=1)               # (N, C)\n        preds = torch.argmax(outputs, dim=1)\n\n        y_true_test.extend(labels.cpu().numpy())\n        y_pred_test.extend(preds.cpu().numpy())\n        # take positive class prob (assume class index 1 is 'CANCER' or adjust accordingly)\n        if probs.shape[1] == 2:\n            y_prob_test.extend(probs[:, 1].cpu().numpy())\n        else:\n            # for multiclass you might want one-vs-rest AUC per class\n            y_prob_test.extend(probs.cpu().numpy())\n\n# Metrics\ny_true_test = np.array(y_true_test)\ny_pred_test = np.array(y_pred_test)\nprint(\"\\n=== Test set results ===\")\nacc_test = accuracy_score(y_true_test, y_pred_test)\nprec_test = precision_score(y_true_test, y_pred_test, average='binary' if len(class_names)==2 else 'macro', zero_division=0)\nrec_test = recall_score(y_true_test, y_pred_test, average='binary' if len(class_names)==2 else 'macro', zero_division=0)\nf1_test = f1_score(y_true_test, y_pred_test, average='binary' if len(class_names)==2 else 'macro', zero_division=0)\n\nprint(f\"Test Accuracy: {acc_test:.4f}\")\nprint(f\"Test Precision: {prec_test:.4f}\")\nprint(f\"Test Recall: {rec_test:.4f}\")\nprint(f\"Test F1-score: {f1_test:.4f}\")\n\ncm = confusion_matrix(y_true_test, y_pred_test)\nprint(\"Confusion Matrix:\\n\", cm)\nprint(\"Classification Report:\\n\", classification_report(y_true_test, y_pred_test, target_names=class_names, zero_division=0))\n\n# ROC & AUC for binary\nif len(class_names) == 2:\n    y_prob_test = np.array(y_prob_test)\n    fpr, tpr, thresholds = roc_curve(y_true_test, y_prob_test)\n    roc_auc = auc(fpr, tpr)\n    print(f\"Test AUC: {roc_auc:.4f}\")\n\n    # Plot ROC curve (optional)\n    plt.figure(figsize=(6,6))\n    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')\n    plt.plot([0,1], [0,1], 'k--', linewidth=0.6)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Test ROC Curve')\n    plt.legend(loc='lower right')\n    plt.grid(alpha=0.3)\n    plt.show()\n\nprint(f\"\\nFinal model file saved at: {SAVE_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"TEST WITH EXTERNAL IMAGES","metadata":{}},{"cell_type":"code","source":"model = models.densenet169(pretrained=False)\nmodel.classifier = nn.Linear(model.classifier.in_features, 2)\n\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_cv_model.pkl\", map_location=DEVICE))\nmodel = model.to(DEVICE)\nmodel.eval()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_image(image_path):\n    # Load image\n    image = Image.open(image_path).convert(\"RGB\")\n    image = eval_transform(image).unsqueeze(0).to(DEVICE)\n\n    # Inference\n    with torch.no_grad():\n        outputs = model(image)\n        probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n\n    pred_idx = np.argmax(probs)\n    pred_class = CLASS_NAMES[pred_idx]\n    confidence = probs[pred_idx]\n\n    return pred_class, confidence, probs\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/datasets/ashenafifasilkebede/dataset/test/Normal/Normal_100x_12.jpg\"  # change path\n\npred_class, confidence, probs = predict_image(image_path)\n\nprint(\"Prediction:\", pred_class)\nprint(\"Confidence:\", round(confidence * 100, 2), \"%\")\nprint(\"Probabilities:\", probs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}